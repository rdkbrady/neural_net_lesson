{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Neural Networks\n",
    "\n",
    "Learning objectives:\n",
    "1. Understand what neural networks can do.\n",
    "2. Understand the structure of a neural network.\n",
    "3. Understand forward propagation and backpropagation.\n",
    "4. Understand the structure of a neuron, and be able to select appropriate activation functions.\n",
    "5. Implement a neural network in keras\n",
    "\n",
    "Prerequisites:\n",
    "1. derivatives, including partial derivatives\n",
    "2. gradient descent\n",
    "3. chain rule\n",
    "\n",
    "Some very good videos from 3 blue 1 brown:\n",
    "- [Neural Network playlist (4 videos)](https://www.youtube.com/watch?v=aircAruvnKk&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Applications of Neural Networks\n",
    "\n",
    "\n",
    "### Text Generation\n",
    "The [GPT-2](http://jalammar.github.io/illustrated-gpt2/) model is a **decoder** model which uses previous words to predict the next one in a sequence. You can experiment with a limited version of this model at [talk to transformer](https://talktotransformer.com/). \n",
    "\n",
    "**Input:** In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
    "\n",
    "**Output:** The amazing find was made by researchers of the Universidad Austral de Chile, thanks to one of the country's most highly active amateur scientists. Of course, the creature in question was not a real unicorn, but a llama, and unfortunately the strange creature was killed before researchers could analyze its vocalization.\n",
    "\n",
    "\n",
    "### Image Classification\n",
    "The [VGG-16](https://neurohive.io/en/popular-networks/vgg16/) model is a **deep convolutional** network that can classify image regardless of the scale or rotation of the objects in the image.\n",
    "\n",
    "doge? | doge?\n",
    "- | - \n",
    "[<img src=\"img/shibe.jpg\" width=240 />](https://knowyourmeme.com/memes/doge) |[<img src=\"img/doge.jpg\" width=240 />](https://en.wikipedia.org/wiki/Doge_of_Venice)\n",
    "\n",
    "\n",
    "# Teacher Note: don't spend time on these.\n",
    "### Image Generation\n",
    "[Generative adversarial networks](https://neurohive.io/en/news/deepfake-videos-gan-sythesizes-a-video-from-a-single-photo/]) can be used to create plausible images and video.\n",
    "<img src=\"img/gan.png\" width=600 />\n",
    "\n",
    "### AI\n",
    "AlphaZero is a neural network AI that has beaten world champions in [Chess](https://www.chess.com/news/view/updated-alphazero-crushes-stockfish-in-new-1-000-game-match), [Go](https://www.theverge.com/2019/11/27/20985260/ai-go-alphago-lee-se-dol-retired-deepmind-defeat), and [Starcraft](https://www.theverge.com/2019/10/30/20939147/deepmind-google-alphastar-starcraft-2-research-grandmaster-level)\n",
    "\n",
    "[OpenAI](https://openai.com/blog/solving-rubiks-cube/) has also applied neural networks to solving physical robotics problems.\n",
    "\n",
    "<img src=\"img/rubiks.jpg\" width=600 />\n",
    "\n",
    "### Other applications\n",
    "\n",
    "Many machine learning techniques can also be implemented through neural networks (linear regression, logistic regression, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Structure of a Neural Network\n",
    "\n",
    "Black Box view:\n",
    "<img src=\"img/black_box.png\" width=600 />\n",
    "Layer view:\n",
    "<img src=\"img/layers.png\" width=600 />\n",
    "\n",
    "# Teacher Note: Clarify which pieces we set, which are trained.\n",
    "# Q: Ask about dimension of weights\n",
    "Neuron view:\n",
    "<img src=\"img/layers_with_neurons.png\" width=600 />\n",
    "\n",
    "# Teacher Note: Clarify Notation\n",
    "\n",
    "As functions:\n",
    "$$\\mathbf{y} = \\mathbf{f}_y(\\mathbf{W}_4, \\mathbf{b}_4, \\mathbf{h}_3)$$\n",
    "$$\\mathbf{h}_3 = \\mathbf{f}_{h(3)}(\\mathbf{W}_3, \\mathbf{b}_3, \\mathbf{h}_2)$$\n",
    "$$\\mathbf{h}_2 = \\mathbf{f}_{h(2)}(\\mathbf{W}_2, \\mathbf{b}_2, \\mathbf{h}_1)$$\n",
    "$$\\mathbf{h}_1 = \\mathbf{f}_{h(1)}(\\mathbf{W}_1, \\mathbf{b}_1, \\mathbf{x})$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Forward propagation and backpropagation\n",
    "\n",
    "## Forward propagation: \n",
    "1. Calculate first hidden layer from inputs\n",
    "2. Calculate second hidden layer from first hidden layer\n",
    "3. etc.\n",
    "4. Calculate outputs from last hidden layer\n",
    "\n",
    "\n",
    "In terms of the functions above,\n",
    "1. $$\\mathbf{h}_1 = \\mathbf{f}_{h(1)}(\\mathbf{W}_1, \\mathbf{b}_1, \\mathbf{x})$$\n",
    "2. $$\\mathbf{h}_2 = \\mathbf{f}_{h(2)}(\\mathbf{W}_2, \\mathbf{b}_2, \\mathbf{h}_1)$$\n",
    "3. $$\\mathbf{h}_3 = \\mathbf{f}_{h(3)}(\\mathbf{W}_3, \\mathbf{b}_3, \\mathbf{h}_2)$$\n",
    "4. $$\\mathbf{y} = \\mathbf{f}_y(\\mathbf{W}_4, \\mathbf{b}_4, \\mathbf{h}_3)$$\n",
    "\n",
    "# Teacher Note: Ask about gradient descent\n",
    "\n",
    "And we can calculate the value of a cost function:\n",
    "$$C(\\mathbf{y}, \\mathbf{y}_{obs})$$\n",
    "\n",
    "## Backpropagation \n",
    "Backpropagation is how we find the gradient across all weights so that we can do gradient descent. \n",
    "\n",
    "Review:\n",
    "- Chain Rule\n",
    "\n",
    "$$ z =  f(g(x)) $$\n",
    "$$ u = g(x) $$\n",
    "$$ \\frac{dz}{dx} =  \\frac{dz}{du} \\frac{du}{dx}$$\n",
    "\n",
    "For example:\n",
    "$$ \\frac{dC}{dW_3} = \\frac{dC}{d\\mathbf{y}}\\frac{d\\mathbf{y}}{d\\mathbf{h}_3}\\frac{d\\mathbf{h}_3}{d\\mathbf{W}_3} $$\n",
    "\n",
    "In general:\n",
    "$$ \n",
    "\\frac{dC}{dW_i} = \n",
    "    \\frac{dC}{d\\mathbf{y}}\n",
    "    \\frac{d\\mathbf{y}}{d\\mathbf{h}_m}\n",
    "    \\frac{d\\mathbf{h}_m}{d\\mathbf{h}_{m-1}} ... \n",
    "    \\frac{d\\mathbf{h}_{i+1}}{d\\mathbf{h}_{i}}\n",
    "    \\frac{d\\mathbf{h}_{i}}{d\\mathbf{W}_{i}}\n",
    "$$\n",
    "\n",
    "Or more compactly, \n",
    "$$   \\frac{dC}{dW_i} = \\frac{dC}{dh_{i}}\\frac{dh_{i}}{dW_i}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Building a simple artificial neuron\n",
    "\n",
    "\n",
    "[<img src=\"img/neuron.jpg\" width=400 />](https://medium.com/@jayeshbahire/the-artificial-neural-networks-handbook-part-4-d2087d1f583e)\n",
    "\n",
    "\n",
    "We will use the Rectified Linear Unit or [ReLU](https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/) as our activation function: \n",
    "\n",
    "$$    ReLU(x) = \\Bigg\\{\n",
    "        \\begin{array}{ll}\n",
    "        x, & \\text{if } x > 0\\\\\n",
    "        0, & \\text{otherwise }\\\\\n",
    "        \\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts import demo\n",
    "\n",
    "inputs = demo.make_inputs(5)\n",
    "weights, bias = demo.initialize_neuron(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    '''\n",
    "    Params\n",
    "    ———-\n",
    "    x: float\n",
    "    \n",
    "    Returns\n",
    "    ———-\n",
    "    output: float\n",
    "    '''\n",
    "    if(x > 0):\n",
    "        output = x\n",
    "    else:\n",
    "        output = 0\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write this together\n",
    "def neuron(prev_layer, weights, bias, activation_function):\n",
    "    '''\n",
    "    Params\n",
    "    ———-\n",
    "    prev_layer: numpy.ndarray\n",
    "        Should have shape (m, ). Contains output values from the previous layer.\n",
    "    weights: numpy.ndarray \n",
    "        Should have shape (m, ). Contains weights connecting previous layer to this neuron\n",
    "    bias: float\n",
    "    activation_function: function(float)\n",
    "    \n",
    "    Returns\n",
    "    ———-\n",
    "    output: float\n",
    "        the output of the neuron\n",
    "\n",
    "    '''\n",
    "    weighted_sum = sum(prev_layer * weights) + bias\n",
    "    output = activation_function(weighted_sum)\n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For backpropagation, we'll also need a way to get derivatives across a neuron. \n",
    "\n",
    "$$ \\varphi(z) = \\Bigg\\{\n",
    "        \\begin{array}{ll}\n",
    "        z, & \\text{if } z > 0\\\\\n",
    "        0, & \\text{otherwise }\\\\\n",
    "        \\end{array} $$\n",
    "$$ z = w_1x_1 + w_2x_2 + ... + w_mx_m + b$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q: Ask about vanishing gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_relu(x):\n",
    "    '''\n",
    "    Params\n",
    "    ———-\n",
    "    x: float\n",
    "    \n",
    "    Returns\n",
    "    ———-\n",
    "    output: float\n",
    "    '''\n",
    "    if x > 0:\n",
    "        output = 1\n",
    "    else:\n",
    "        output = 0\n",
    "    return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivative_neuron(prev_layer, weights, bias, neuron_output, d_activation):\n",
    "    '''\n",
    "    Params\n",
    "    ———-\n",
    "    prev_layer: numpy.ndarray\n",
    "        Should have shape (m, ). Contains output values from the previous layer.\n",
    "    weights: numpy.ndarray \n",
    "        Should have shape (m, ). Contains weights connecting previous layer to this neuron\n",
    "    bias: float\n",
    "    activation_function: function(float)\n",
    "    neuron_output: float\n",
    "        This is the output of this neuron from forward propagation\n",
    "    d_activation: function\n",
    "        the derivative of the activation function\n",
    "\n",
    "        \n",
    "    Returns\n",
    "    ———-\n",
    "    output: float\n",
    "        the output of the neuron\n",
    "\n",
    "    '''\n",
    "    d_dw = prev_layer * d_activation(neuron_output)\n",
    "    d_dl = weights * d_activation(neuron_output)\n",
    "    d_db = d_activation(neuron_output)\n",
    "    return d_dw, d_dl, d_db\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: [-0.43276767 -0.45503845  0.19463214 -0.38859406 -0.44386373]\n",
      "weights: [-0.1742682  -0.24403437 -0.81542457 -0.88443157 -0.03426628]\n",
      "bias: 0.8482223223499666\n",
      "output: 1.2348715693977441\n",
      "\n",
      "d/dw: [-0.43276767 -0.45503845  0.19463214 -0.38859406 -0.44386373]\n",
      "d/dl: [-0.1742682  -0.24403437 -0.81542457 -0.88443157 -0.03426628]\n",
      "d/db: 1\n"
     ]
    }
   ],
   "source": [
    "# Test the neuron function. (inputs, weights, bias are imported from the demo script)\n",
    "inputs = demo.make_inputs(5)\n",
    "weights, bias = demo.initialize_neuron(5)\n",
    "\n",
    "\n",
    "print(\"inputs: {}\".format(inputs))\n",
    "print(\"weights: {}\".format(weights))\n",
    "print(\"bias: {}\".format(bias))\n",
    "print(\"output: {}\".format(neuron(inputs, weights, bias, relu)))\n",
    "\n",
    "neuron_output = neuron(inputs, weights, bias, relu)\n",
    "d_dw, d_dl, d_db = derivative_neuron(inputs, weights, bias, neuron_output, d_relu)\n",
    "\n",
    "print(\"\")\n",
    "print(\"d/dw: {}\".format(d_dw))\n",
    "print(\"d/dl: {}\".format(d_dl))\n",
    "print(\"d/db: {}\".format(d_db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Recognizing Handwritten Digits\n",
    "\n",
    "Just use Keras!\n",
    "\n",
    "Example from https://www.tensorflow.org/datasets/keras_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x13f6bd520>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "train, test = demo.mnist_data()\n",
    "\n",
    "plt.matshow(next(tfds.as_numpy(train))[0][0][:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.3865 - accuracy: 0.8918 - val_loss: 0.1999 - val_accuracy: 0.9400\n",
      "Epoch 2/6\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1654 - accuracy: 0.9510 - val_loss: 0.1476 - val_accuracy: 0.9564\n",
      "Epoch 3/6\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1213 - accuracy: 0.9643 - val_loss: 0.1120 - val_accuracy: 0.9669\n",
      "Epoch 4/6\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0961 - accuracy: 0.9713 - val_loss: 0.1007 - val_accuracy: 0.9690\n",
      "Epoch 5/6\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0804 - accuracy: 0.9759 - val_loss: 0.0916 - val_accuracy: 0.9734\n",
      "Epoch 6/6\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0671 - accuracy: 0.9798 - val_loss: 0.0929 - val_accuracy: 0.9727\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x140385d00>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Flatten())\n",
    "# hidden layers\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "# output layer\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train,\n",
    "    epochs=6,\n",
    "    validation_data=test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network thinks this image is a 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x13f8a0f40>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Examine predictions\n",
    "batch_index = 0\n",
    "\n",
    "example = next(tfds.as_numpy(test))[0]\n",
    "print(\"Network thinks this image is a {}\".format(np.argmax(model.predict(example)[batch_index])))\n",
    "plt.matshow(example[batch_index,:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What else would we do in a full day lesson?\n",
    "\n",
    "- Implement the training of a neural network using numpy.\n",
    "- Go over all commonly used activation functions and discuss the pros/cons of each. \n",
    "- Understand what vanishing gradient means, and how that applies to choice of activation function\n",
    "- Go over commonly used cost functions\n",
    "- Learn how GPUs can be used to accelerate the training of neural nets.\n",
    "- Overview of convolutional layers, GRUs and LSTMs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What I had difficulty with\n",
    "- What are the conventions for notation of vectors, matrices, derivatives of those, etc.?\n",
    "- Timing (expect to get better with this with practice)\n",
    "- Technology. Ideally I'd like to provide a docker image with notebooks for all students. \n",
    "- Whiteboarding online?\n",
    "- Slow down and ask questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:neural]",
   "language": "python",
   "name": "conda-env-neural-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
